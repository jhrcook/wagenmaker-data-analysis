---
title: "Analyzing the results of \"Registered Replication Report: Strack, Martin, and Stepper (1988)\""
description: |
  My own visualization and statistical analysis of the data from a replication study of this famous phsycology paper.
author:
  - first_name: "Joshua"
    last_name: "Cook"
    url: https://joshuacook.netlify.app
    orcid_id: 0000-0001-9815-6879
date: "May 23, 2021"
output:
  distill::distill_article:
    toc: true
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = "#>", dpi = 400)

library(mustashe)
library(nakedpipe)
library(magrittr)
library(glue)
library(patchwork)
library(tidyverse)

theme_set(
  theme_minimal() +
    theme(
      strip.text = element_text(face = "bold"),
      plot.title = element_text(hjust = 0.5)
    )
)
```

## Introduction

### Background

In his famous book, [*Thinking Fast and Slow*](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow), [Daniel Kahneman](https://en.wikipedia.org/wiki/Daniel_Kahneman) describes how our mind acts in many ways that we are completely unaware of.
One such phenomenon is "priming" where one event (e.g. hearing a word spoken, seeing an image) brings associated ideas into our mind and available for faster recall than other terms.
One form of priming is that a physical movement we make can affect how our mind behave.

One example that Kahneman provides was illustrated by Strack *et al.* in 1988 where they asked participants to rate their perceived level of amusement of several [The Far Side](https://en.wikipedia.org/wiki/The_Far_Side) cartoons [@Strack1988-zd].
The caveat was that the participants viewed the comics while holding a pencil with their teeth, either sideways with the eraser pointing to their right or pointing forwards with the eraser between their teeth.
The first pose induces a facial expression similar to smiling whereas the latter causes a frowning motion, but the participants are unaware of this effect.
This acts as a primer to make the participants easier or harder to amuse, respectively, and this was measured by a reduced rating of the cartoons by the frowning group.

This was just one example provided by Kahneman, but I was curious about the actual effect size of these phenomenon.
Is this causing swings from elation to depression, or from mild pleasure to mild displeasure?
How influential were these priming effects?
So I decided to look up this paper, "Inhibiting and Facilitating Conditions of the Human Smile: A Nonobtrusive Test of the Facial Feedback Hypothesis" ([PDF](papers/Strack_1988_Inhibiting-and-facilitating-conditions-of-the-human-smile-a-nonobtrusive-test-of-the-facial-feedback-hypothesis.pdf)), and do some analysis for myself.
Unfortunately, the original data is not provided with the paper, but I did find a replication of the experiment, "Registered Replication Report: Strack, Martin, & Stepper (1988)" ([PDF](papers/Acosta-et-al_2016_APS.pdf)) [@Acosta2016-bj].
I was able to acquire this data set and conduct a statistical analysis for myself.

### Experimental procedure

Below is the experimental producer of the replication report [@Acosta2016-bj].

>Participants worked through the tasks in the task booklet while holding the pen in their mouth.
> The first task was to draw lines between a series of successive numbers and the second task was to underline vowels.
> The third and crucial task was to rate how amused they were by four cartoons.
> For each cartoon, participants answered the question “What feeling was elicited in you by looking at the cartoon?” by using a 10-point Likert scale ranging from 0 (I felt not at all amused) to 9 (I felt very much amused).
>
>After these tasks, participants removed the pen from their mouths and completed an exit questionnaire that asked three questions: (a) “How successful were you in holding the pen in the correct position during the entire experimental session?” (the answer was indicated on a 10-point Likert scale, as in SMS Study 2); (b) “Did you understand the cartoons?” (yes/no); and (c) “What do you think the purpose of this experiment is?” (open-ended).

Below is an image demonstrating the positions.

```{r pencil-demo, fig.cap="Demonstration of holding the pencil to force a smile (left) or frown (right) [@Acosta2016-bj]."}
knitr::include_graphics("papers/Acosta_2016_fig1.png")
```

There were a few criteria by which a data point or participant could be excluded from the data set.
There are reproduced below and the excluded data points were indicated in the published data set.

> Exclusion criteria were deliberately strict.
> Data were excluded from participants whose average cartoon rating exceeded 2.5 standard deviations from the group mean in their condition.
> Data were excluded if, based on the exit questionnaire, participants correctly guessed the goal of the study (i.e., the position of the pen influences the funniness ratings for the cartoons).
> Data were also excluded if a participant answered “No” to the question “Did you understand the cartoons?”.
> Finally, data were excluded from participants who held the pen incorrectly for two or more of the cartoons (based on the video recordings).
> If participants held the pen incorrectly for just one cartoon, data from that cartoon rating were excluded from analyses.

## Data preparation

Below is the code for preparing the data.
Two subjects, 63 and 39, were removed because they had a lot of missing data points.
Otherwise, the data was left as is and only rearranged for ease of use in data visualization and modeling.

```{r, echo=TRUE}
subjects_to_remove <- c("63", "39")

# CLean the initial data columns.
data <- read_csv("data/Wagenmakers-data_modified.csv") %.% {
  janitor::clean_names()
  mutate(
    subject_number = factor(subject_number),
    participant_id = factor(participant_id),
    across(starts_with("cartoon") & ends_with("correct"), as.logical),
    aware_of_goal = as.logical(aware_of_goal),
    comprehension_of_cartoons = as.logical(comprehension_of_cartoons),
    student = as.logical(student),
    gender = case_when(
      gender == 1 ~ "M",
      gender == 0 ~ "F",
      TRUE ~ NA_character_
    )
  )
  filter(!subject_number %in% subjects_to_remove)
}

# Pivot the data into a long format.
data <- data %.% {
  select(-contains("task"), -guess_of_purpose)
  pivot_longer(cols = c(contains("cartoon"), -comprehension_of_cartoons))
  mutate(name = str_remove(name, "^cartoon_"))
  separate(name, into = c("cartoon_number", "variable"), sep = "_")
  pivot_wider(names_from = variable, values_from = value)
  mutate(
    correct = as.logical(correct),
    cartoon_number = glue::glue("Cartoon {cartoon_number}"),
    condition = ifelse(condition, "frown", "smile")
  )
}
```

We can see that there are a few subjects whose occupation is unknown and there is one missing cartoon rating data point (belonging to subject 31).

```{r}
naniar::miss_var_summary(data) %>%
  filter(n_miss > 0) %>%
  rename(
    `num. missing` = n_miss,
    `percent missing` = pct_miss
  ) %>%
  kableExtra::kbl() %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "responsive")
  )
```

Per the original experimental design and protocol, subjects were excluded if they:

- were aware of the research goal,
- did not understand the cartoons

```{r, echo=TRUE}
excluded_subjects <- data %.% {
  filter(aware_of_goal | !comprehension_of_cartoons | total_correct <= 2)
  pull(subject_number)
  unlist()
  unique()
}

data <- data %>%
  mutate(excluded_data = subject_number %in% excluded_subjects)
```

This resulted in `r length(excluded_subjects)` subjects that were excluded from the analysis.

## Data visualization

As always, it is important to visualize the data before statistical analysis.
The goal is to get a general understanding for the scale of effect sizes and patterns that will be tested later.

The plot below shows the distribution of ratings for each of the four cartoons, separated by the frown/smile experimental condition.
Visually, there does not appear to be much of a difference.

```{r}
data %>%
  filter(!is.na(rating)) %>%
  ggplot(aes(x = condition, y = rating, color = condition)) +
  facet_wrap(~cartoon_number) +
  geom_point(
    size = 1,
    alpha = 0.5,
    position = position_jitterdodge(
      jitter.width = 0.4,
      jitter.height = 0.25,
      seed = 0
    ),
    show.legend = FALSE
  ) +
  geom_boxplot(
    aes(fill = condition),
    alpha = 0.2,
    outlier.shape = NA
  ) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  labs(x = NULL, y = "rating")
```

We can further subdivide the participants by sex, but this does not reveal a strong pattern, either.

```{r}
data %>%
  filter(!is.na(rating)) %>%
  ggplot(aes(x = condition, y = rating)) +
  facet_wrap(~cartoon_number) +
  geom_point(
    aes(color = gender),
    size = 1,
    alpha = 0.5,
    position = position_jitterdodge(
      jitter.width = 0.2,
      jitter.height = 0.25,
      seed = 0
    ),
    show.legend = FALSE
  ) +
  geom_boxplot(
    aes(color = gender, fill = gender),
    alpha = 0.2,
    outlier.shape = NA
  ) +
  scale_color_brewer(type = "qual", palette = "Set2") +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  labs(x = NULL, y = "rating")
```

The next plot presents the distribution of rating scores per cartoon for the two conditions side-by-side.
If we assume that these distributions can be approximated by Gaussian distributions, there does not seem to be a difference between the two groups.

```{r}
rating_counts <- data %.% {
  filter(!is.na(rating) & !excluded_data)
  count(condition, rating, cartoon_number)
  tidyr::complete(condition, rating, cartoon_number, fill = list(n = 0))
  group_by(condition, cartoon_number)
  mutate(frac = n / sum(n))
  ungroup()
}


rating_counts %>%
  ggplot(aes(x = factor(rating), y = n)) +
  facet_wrap(~cartoon_number, nrow = 2) +
  geom_col(aes(fill = condition), position = "dodge") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  scale_y_continuous(expand = expansion(c(0, 0.02))) +
  theme(legend.position = "bottom") +
  labs(
    x = "cartoon rating",
    y = "count",
    fill = "condition"
  )
```

Instead of showing the number of different ratings for each cartoon in each experimental condition, we can subtract one the counts of one from the other.
This is shown below, where the number of each rating in the frown condition is subtract from that of the smiling condition.
If a cartoon was rated higher in the smiling condition than in the frowning condition, we would expect to see a general increase in the plots from left to right.
Instead, there is no obvious trend and the line wanders around 0 indicating a lack of a trend.

```{r}
rating_counts %.%
  {
    select(-n)
    pivot_wider(names_from = condition, values_from = frac)
    mutate(difference = smile - frown)
  } %>%
  ggplot(aes(x = factor(rating), y = difference)) +
  facet_wrap(~cartoon_number) +
  geom_hline(yintercept = 0) +
  geom_line(
    group = 1,
    alpha = 0.2,
    size = 0.9,
    color = "black"
  ) +
  geom_point(aes(color = difference), size = 2.5) +
  scale_color_gradient2(
    low = "blue",
    high = "red",
    mid = "grey70",
    guide = FALSE
  ) +
  labs(
    x = "cartoon rating",
    y = "diff. fraction (smile - frown)"
  )
```

Another factor to consider is the age of the participant.
It is possible that some cartoons appealed to people of different ages due to different perceptions of cultural references, political affiliations, etc.
From the plot below, we can see that most patients were around 20 years old and there is no correlation between age of the participant and their average rating of the cartoons.

```{r, message=FALSE, warning=FALSE}
rating_summaries <- data %>%
  filter(!is.na(rating)) %>%
  group_by(
    participant_id,
    condition,
    gender,
    comprehension_of_cartoons,
    correct,
    excluded_data
  ) %>%
  summarize(
    avg_rating = mean(rating),
    avg_age = mean(age)
  ) %>%
  ungroup()
```

```{r}
age_vs_rating_historgram_factory <- function(d, x, flipped = FALSE) {
  x_vals <- d %>%
    pull({{ x }}) %>%
    unlist()
  min_x <- min(x_vals)
  max_x <- max(x_vals)
  p <- d %>%
    ggplot(aes(x = {{ x }})) +
    geom_histogram(aes(y = after_stat(density)), bins = 30) +
    geom_density(fill = "gray50", alpha = 0.3) +
    scale_x_continuous(
      expand = expansion(c(0.02, 0.02)),
      limits = c(min_x, max_x)
    ) +
    scale_y_continuous(expand = expansion(c(0, 0.02)))

  if (flipped) {
    p <- p +
      coord_flip() +
      theme(
        axis.text.y = element_blank(),
        axis.title.y = element_blank()
      )
  } else {
    p <- p +
      theme(
        axis.text.x = element_blank(),
        axis.title.x = element_blank()
      )
  }

  return(p)
}


age_hist <- age_vs_rating_historgram_factory(rating_summaries, x = avg_age)
rating_hist <- age_vs_rating_historgram_factory(
  rating_summaries,
  x = avg_rating,
  flipped = TRUE
)

age_vs_rating_main <- rating_summaries %>%
  ggplot(aes(x = avg_age, y = avg_rating)) +
  geom_jitter(
    aes(color = condition, shape = excluded_data),
    width = 0.5,
    height = 0.1,
    size = 1.5,
    alpha = 0.7
  ) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_shape_manual(values = c(19, 4), labels = c("included", "excluded")) +
  scale_x_continuous(expand = expansion(c(0.02, 0.02))) +
  scale_y_continuous(expand = expansion(c(0.02, 0.02))) +
  theme(legend.position = "bottom") +
  labs(
    x = "avgerage age",
    y = "average cartoon rating",
    color = NULL,
    shape = NULL
  )

layout <- "
AAAAA#
CCCCCB
CCCCCB
CCCCCB
CCCCCB
"

(age_hist + rating_hist + age_vs_rating_main) + plot_layout(design = layout)
```

## Analysis

Below is a statisical analysis of the main question of the study: does the act of smiling or frowning influence a participants perception of cartoons?
We will use a Bayesian data analysis framework focused around the ['rstanarm'](https://CRAN.R-project.org/package=rstanarm) ([documentation](https://mc-stan.org/rstanarm/)) package and build hierarchical mixed-effects models to try to explain the influence of avarious experimental factors on the cartoon ratings.

```{r, message=FALSE, warning=FALSE}
library(bayestestR)
library(see)
library(tidybayes)
library(bayesplot)
library(rstanarm)
```

```{r}
model_data <- data %.% {
  filter(!excluded_data)
  filter(correct)
  mutate(cartoon_number = factor(cartoon_number))
}
```


# Model 1. Covariate per cartoon

Simple model: `rating ~ 1 + cartoon_number`

```{r, echo=TRUE}
stash("m1", depends_on = "model_data", {
  m1 <- stan_lm(
    rating ~ 1 + cartoon_number,
    data = model_data,
    prior = R2(0.5),
    prior_intercept = normal(0, 5),
    seed = 0,
    cores = 2
  )
  m1$loo <- rstanarm::loo(m1, cores = 2)
  m1
})

m1
```

The chains mix well and converge.

```{r}
mcmc_trace(m1, pars = c("(Intercept)", glue("cartoon_numberCartoon {c(2:4)}")))
```

The posterior distributions for the cartoons (Cartoon 1 is represented as the intercept) look good.
They suggest that, on average, cartoon 2 and 4 were funnier than 1 and 3.

```{r}
mcmc_areas(
  as.matrix(m1),
  pars = c("(Intercept)", glue("cartoon_numberCartoon {c(2:4)}")),
  prob = 0.89
)
```

This simple model really just estimates the average rating for each cartoon.

```{r}
plotdata <- model_data %.% {
  select(cartoon_number, rating)
  mutate(pred = predict(m1))
  pivot_longer(c(rating, pred))
}

ggplot(plotdata, aes(x = value)) +
  facet_wrap(~cartoon_number) +
  geom_density(aes(color = name, fill = name), alpha = 0.2, size = 1)
```

### Model 2. Covariates per cartoon and experimental condition

```{r, echo=TRUE}
stash("m2", depends_on = "model_data", {
  m2 <- stan_lm(
    rating ~ 1 + cartoon_number + condition,
    data = model_data,
    prior = R2(0.5),
    prior_intercept = normal(0, 5),
    seed = 0,
    cores = 4
  )
  m2$loo <- rstanarm::loo(m2, cores = 2)
  m2
})

m2
```

Even in this simple model, there is no evidence that the experimental condition (frown vs. smile) has any effect.

```{r}
mcmc_areas(
  as.matrix(m2),
  pars = c(
    "(Intercept)",
    glue("cartoon_numberCartoon {c(2:4)}"),
    "conditionsmile"
  ),
  prob = 0.89
)
```

### Model 3. Varying intercepts per subject and cartoon

Model 3: `rating ~ (1 | subject_number) + (1 | cartoon_number) + condition`.

A varying intercept per subject (132) and cartoon (4) with a single factor for the experimental condition where the intercept incorporates the frown group and the smile group is represented by `conditionsmile`.

```{r, echo = TRUE}
stash("m3", depends_on = "model_data", {
  m3 <- stan_lmer(
    rating ~ (1 | subject_number) + (1 | cartoon_number) + condition,
    data = model_data,
    seed = 0,
    cores = 3
  )
  m3$loo <- rstanarm::loo(m3, cores = 3, k_threshold = 0.7)
  m3
})

m3
```

```{r message=FALSE, warning=FALSE}
as_tibble(
  bayestestR::describe_posterior(
    m3,
    effects = "all",
    parameters = "smile|cartoon"
  )
) %>%
  select(-Effects)
```
Looking at the posterior distributions of the covariates, we can see again that cartoons 2 and 4 tended to be more amusing than 1 and 3. However, the posterior for the smile covariate stradles 0, indicating this experimental condition had no effect on the rating.

```{r}
m3_post_main <- as.data.frame(m3) %>%
  as_tibble() %>%
  select(!contains("subject_number"))

m3_post_main %>%
  select(-`Sigma[cartoon_number:(Intercept),(Intercept)]`) %>%
  mutate(sample_id = row_number()) %>%
  pivot_longer(-sample_id) %>%
  mutate(
    name = str_remove(name, "^b\\[\\(Intercept\\) cartoon_number\\:"),
    name = str_remove(name, "\\]$"),
    name = str_remove(name, "^condition"),
    name = str_replace_all(name, "_", " "),
    name = fct_rev(fct_inorder(name))
  ) %>%
  ggplot(aes(value, name)) +
  geom_vline(xintercept = 0, linetype = 2) +
  ggridges::geom_density_ridges(alpha = 0.4, bandwidth = 0.05) +
  scale_x_continuous(expand = c(0, 0)) +
  labs(
    x = "posterior",
    y = NULL,
    title = "Posterior distribtions for model 3"
  )
```

Below are the estimated varying effects for participants.
Most were small, but a few participants were consistently less amused or more amused by the cartoons.

```{r}
as_tibble(
  bayestestR::describe_posterior(
    m3,
    effects = "random",
    paramters = "subject_number"
  )
) %>%
  filter(Effects == "random") %>%
  arrange(Median) %>%
  mutate(Parameter = fct_inorder(Parameter)) %>%
  ggplot(aes(Parameter)) +
  geom_hline(yintercept = 0, linetype = 2, alpha = 0.5) +
  geom_linerange(aes(ymin = CI_low, ymax = CI_high), alpha = 0.2) +
  geom_point(aes(y = Median, color = Median), alpha = 0.7, size = 1) +
  scale_color_gradient2(mid = "grey80") +
  theme(
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank()
  ) +
  labs(
    x = "participants",
    y = "posterior distribution",
    title = "Particiapnt varying intercepts",
    color = "median"
  )
```

### Model 4. Description...

Model 4: `rating ~ (1 | subject_number) + (1 | cartoon_number) + condition + gender + student + age`

Now use all available factors including the sex and age of the participant and whether or not they were a student.

```{r, echo=TRUE}
stash("m4", depends_on = "model_data", {
  m4 <- stan_lmer(
    rating ~ (1 | subject_number) +
      (1 | cartoon_number) +
      condition + gender + student + age,
    data = model_data,
    seed = 0,
    cores = 2
  )
  m4$loo <- rstanarm::loo(m4, cores = 2)
  m4
})

m4
```

While the smile/frown condition still appears to be inconsequential along with gender, the impact of student and age may be meaningful.
In particular, there may be a small but significant positive assoication between participant age and cartoon rating.

```{r}
mcmc_areas(
  as.matrix(m4),
  pars = c("conditionsmile", "genderM", "studentTRUE", "age"),
  prob = 0.89
)
```

```{r}
library(modelr)

new_data_grid <- data_grid(
  model_data,
  condition, cartoon_number,
  age = seq_range(age, 10)
)

m4_posteriors <- as.data.frame(m4) %>%
  as_tibble() %>%
  select(
    `(Intercept)`,
    age,
    conditionsmile,
    tidyselect::contains("b[(Intercept) cartoon_number:Cartoon_")
  ) %>%
  rename(intercept = `(Intercept)`)

colnames(m4_posteriors) <- str_remove(
  colnames(m4_posteriors),
  "b\\[\\(Intercept\\) cartoon_number\\:"
) %>%
  str_remove("\\]")

predictions <- tibble()

for (i in seq(1, nrow(new_data_grid))) {
  d <- unlist(new_data_grid[i, ])
  pred <- m4_posteriors$intercept
  pred <- pred + m4_posteriors$age * as.numeric(d[["age"]])
  if (d[["condition"]] == "smile") {
    pred <- pred + m4_posteriors$age
  }
  cartoon <- glue("Cartoon_{d[['cartoon_number']]}")
  pred <- pred + unname(unlist(m4_posteriors[, cartoon]))
  avg_pred <- mean(pred)
  hdi_pred <- as.numeric(bayestestR::hdi(pred, ci = 0.89))[2:3]
  pred_i <- tibble(
    avg = avg_pred,
    hdi_low = hdi_pred[[1]],
    hdi_high = hdi_pred[[2]]
  )
  predictions <- bind_rows(predictions, pred_i)
}

bind_cols(predictions, new_data_grid) %>%
  ggplot(aes(x = age, y = avg, color = condition)) +
  facet_wrap(~cartoon_number) +
  geom_lineribbon(
    aes(ymin = hdi_low, ymax = hdi_high, fill = condition),
    color = NA,
    alpha = 0.2
  ) +
  geom_line(aes(color = condition)) +
  scale_x_continuous(expand = expansion(c(0, 0))) +
  scale_y_continuous(expand = expansion(c(0.02, 0.02))) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  labs(
    x = "participant age",
    y = "predicted rating",
    color = NULL,
    shape = "condition",
    title = "Predicted ratings by participant age"
  )
```

### Model 5. Varying effect of age per cartoon

```{r, echo=TRUE}
stash("m5", depends_on = "model_data", {
  m5 <- stan_lmer(
    rating ~ (1 | subject_number) +
      (1 + age + condition | cartoon_number) +
      condition + gender + student + age,
    data = model_data,
    seed = 0,
    cores = 4
  )
  m5$loo <- rstanarm::loo(m5, cores = 3)
  m5
})

m5
```

```{r}
bayestestR::describe_posterior(
  m5,
  ci = 0.89,
  parameters = "age",
  effects = "all"
)
```

### Model comparison

Between the 3 models tested, models 2 and 3 were far superior to model 1 which only had covariates for the cartoon.
Model 3 was perhaps slightly better than 2, but the standard error in the comparison is larger than the difference, suggesting that either are reasonable.

```{r}
stash("model_comparison", depends_on = c(glue("m{1:5}"), "model_data"), {
  model_comparison <- loo_compare(m1, m2, m3, m4, m5)
})

model_comparison
```

```{r}
plot_real_vs_predicted <- function(m, data, model_name) {
  m_pred <- as.data.frame(t(as.matrix(posterior_predict(m))))
  m_pred_mean <- apply(m_pred, 1, mean)

  model_data %>%
    mutate(post_pred = m_pred_mean) %>%
    ggplot(aes(rating, post_pred)) +
    geom_jitter(aes(color = post_pred - rating), width = 0.1, height = 0.1) +
    scale_x_continuous(breaks = 0:10) +
    scale_y_continuous(breaks = 0:10) +
    scale_color_gradient2(mid = "grey70") +
    coord_fixed() +
    labs(
      x = "subject rating",
      y = "predicted rating",
      color = "error",
      title = glue("Posterior predictions by {model_name}")
    )
}

plot_real_vs_predicted(m1, model_data, "Model 1")
plot_real_vs_predicted(m2, model_data, "Model 2")
plot_real_vs_predicted(m3, model_data, "Model 3")
plot_real_vs_predicted(m4, model_data, "Model 4")
```

## Conclusions

TODO
